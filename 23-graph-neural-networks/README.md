# Phase 23: Graph Neural Networks

Master Graph Neural Networks (GNNs) for learning on graph-structured data.

## What You'll Learn

- Graph Fundamentals and Representations
- Message Passing in GNNs
- Graph Convolutional Networks (GCNs)
- Graph Attention Networks (GATs)
- GraphSAGE and Other Architectures
- Applications: Social Networks, Recommendation Systems, Molecular Analysis

## Topics Covered

### 1. Graph Fundamentals
- What are graphs and why they matter
- Graph representations (adjacency matrix, edge list)
- Node features, edge features, graph-level features
- Types of graphs (directed, undirected, weighted)

### 2. Message Passing
- Core concept of GNNs
- Neighborhood aggregation
- Information propagation
- Multiple layers and depth

### 3. Graph Convolutional Networks (GCNs)
- Spectral graph convolution
- Spatial graph convolution
- GCN layer implementation
- Training GCNs

### 4. Graph Attention Networks (GATs)
- Attention mechanism for graphs
- Multi-head attention
- GAT architecture
- Advantages over GCNs

### 5. Other GNN Architectures
- **GraphSAGE**: Inductive learning on large graphs
- **GIN**: Graph Isomorphism Networks
- **Graph Transformer**: Transformers for graphs
- **Gated Graph Neural Networks**

### 6. Applications
- Social Network Analysis
- Recommendation Systems
- Molecular Property Prediction
- Knowledge Graphs
- Traffic Prediction
- Fraud Detection

## Learning Objectives

By the end of this module, you should be able to:
- Understand graph data structures and representations
- Implement message passing in GNNs
- Build GCN and GAT models
- Apply GNNs to real-world problems
- Use GNN libraries (PyTorch Geometric, DGL)

## Prerequisites

Before starting this module, you should have completed:
- **Phase 9**: Neural Networks Basics
- **Phase 10**: Deep Learning Frameworks (PyTorch recommended)
- **Phase 12**: Natural Language Processing (helpful for understanding attention)

## Projects

1. **Node Classification**: Classify nodes in citation networks
2. **Link Prediction**: Predict missing edges in social networks
3. **Graph Classification**: Classify molecular graphs
4. **Recommendation System**: Build GNN-based recommender
5. **Knowledge Graph Embedding**: Learn entity and relation embeddings

## Key Concepts

- **Message Passing**: Core mechanism of GNNs
- **Neighborhood Aggregation**: Combine information from neighbors
- **Graph Convolution**: Convolution operation on graphs
- **Attention**: Learn importance of neighbors
- **Inductive vs Transductive**: Generalize to new graphs vs fixed graph

## Documentation & Learning Resources

**Official Documentation:**
- [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/)
- [Deep Graph Library (DGL)](https://www.dgl.ai/)
- [Spektral](https://graphneural.network/) - Keras/TensorFlow

**Free Courses:**
- [CS224W: Machine Learning with Graphs](http://web.stanford.edu/class/cs224w/) - Stanford

**[Complete Detailed Guide →](graph-neural-networks.md)**

**Additional Resources:**
- [Advanced Topics →](graph-neural-networks-advanced-topics.md) - Graph Transformers, Dynamic Graphs, Heterogeneous Graphs
- [Project Tutorial →](graph-neural-networks-project-tutorial.md) - Step-by-step node classification
- [Quick Reference →](graph-neural-networks-quick-reference.md) - Formulas, architectures, code snippets

