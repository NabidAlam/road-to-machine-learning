# Phase 12: Natural Language Processing

Learn to process and understand human language with machine learning.

##  What You'll Learn

- Text Preprocessing
- Word Embeddings (Word2Vec, GloVe)
- Recurrent Neural Networks (RNNs)
- Long Short-Term Memory (LSTM)
- Transformers Basics
- Sentiment Analysis
- Text Classification

##  Topics Covered

### 1. Text Preprocessing
- **Tokenization**: Split text into words/tokens
- **Lowercasing**: Normalize case
- **Removing Punctuation**: Clean text
- **Stop Words**: Remove common words
- **Stemming/Lemmatization**: Reduce words to root form
- **N-grams**: Sequences of n words

### 2. Word Embeddings
- **One-Hot Encoding**: Simple but sparse
- **Word2Vec**: Learn word vectors from context
  - Skip-gram and CBOW
- **GloVe**: Global vectors for word representation
- **FastText**: Handles out-of-vocabulary words
- **Pre-trained Embeddings**: Use existing word vectors

### 3. Recurrent Neural Networks (RNNs)
- **Why RNNs**: Handle sequences
- **Vanilla RNN**: Basic recurrent unit
- **Limitations**: Vanishing gradient problem
- **Applications**: Language modeling, sequence prediction

### 4. Long Short-Term Memory (LSTM)
- **LSTM Cells**: Solve vanishing gradient
- **Gates**: Forget, Input, Output
- **Bidirectional LSTM**: Process both directions
- **Applications**: Sentiment analysis, machine translation

### 5. Transformers (Basics)
- **Attention Mechanism**: Focus on relevant parts
- **Transformer Architecture**: Encoder-Decoder
- **BERT**: Bidirectional Encoder Representations
- **GPT**: Generative Pre-trained Transformer
- **Hugging Face**: Easy access to pre-trained models

### 6. NLP Tasks
- **Sentiment Analysis**: Positive/negative classification
- **Text Classification**: Categorize documents
- **Named Entity Recognition (NER)**: Find entities
- **Machine Translation**: Translate between languages
- **Question Answering**: Answer questions from text

##  Learning Objectives

By the end of this module, you should be able to:
- Preprocess text data
- Create word embeddings
- Build RNN/LSTM models
- Use pre-trained transformer models
- Perform sentiment analysis
- Classify text documents

##  Projects

1. **Sentiment Analysis**: Classify movie reviews
2. **Spam Detection**: Classify emails (NLP approach)
3. **Text Classification**: Categorize news articles
4. **Language Model**: Generate text
5. **Chatbot (Basic)**: Simple conversational agent

##  Key Concepts

- **Sequences**: NLP deals with ordered data
- **Context**: Word meaning depends on context
- **Embeddings**: Dense vector representations
- **Attention**: Focus on relevant information
- **Transfer Learning**: Pre-trained models are powerful

##  Additional Resources

- [CS224n - Stanford NLP](https://web.stanford.edu/class/cs224n/)
- [Hugging Face Course](https://huggingface.co/course)
- [NLTK Book](https://www.nltk.org/book/)
- [spaCy Documentation](https://spacy.io/)

---

**Previous Phase:** [11-computer-vision](../11-computer-vision/README.md)  
**Next Phase:** [13-model-deployment](../13-model-deployment/README.md)

